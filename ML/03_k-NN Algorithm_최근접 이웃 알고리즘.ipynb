{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# k-Nearest Neighbor Algorithm\n",
    "\n",
    "Definition) k-NN Algorithm\n",
    "\n",
    "In pattern recognition, the k-nearest neighbors algorithm (k-NN) is a non-parametric method used for classification and regression.In both cases, the input consists of the k closest training examples in the feature space. The output depends on whether k-NN is used for classification or regression\n",
    "- classification: the output is a class membership. An object is classified by a majority vote of its neighbors, with the object being assigned to the class most common among its k nearest neighbors (k is a positive integer, typically small).\n",
    "- regression: the output is the property value for the object. This value is the average of the values of its k nearest neighbors.\n",
    "\n",
    "### Note) parametric vs Non-parametric\n",
    "\n",
    "## Remark) k-NN 분류\n",
    "예를 들어, $R^n$상의 N개의 학습 데이터가 주어져있다고 하자. 이 때 새로운 데이터에 대해서 그 데이터의 클래스를 결정하고 싶다고 하자.\n",
    "그러면, 새로 주어진 데이터로부터 거리가 $r$인 open ball을 생각해보자.\n",
    "\n",
    "이 때 미리 설정한 k값에 따라 open ball 안에 k개의 학습 데이터가 들어올 때 까지 r을 점점 늘린다.\n",
    "\n",
    "그리고 k개의 학습 데이터가 들어왔을 때, 멈춘 후 그 k개 중에 가장 많은 클래스의 데이터로 주어진 데이터의 클래스를 결정한다.\n",
    "\n",
    "- Figure1.\n",
    "![](./image/img3.png)\n",
    "이미지 출저:https://helloacm.com/a-short-introduction-to-k-nearest-neighbors-algorithm/\n",
    "\n",
    "이해는 이렇게 할 수 있지만, 실제 코드 구현은 open ball을 만들지 않는다.\n",
    "\n",
    "주어진 데이터로부터 학습데이터와의 거리를 모두 잰 다음, 가장 짧은 k개의 데이터를 선택한 다음 클래스를 결정한다.\n",
    "\n",
    "## Remark) k-NN 회귀\n",
    "k-NN 분류와 같은 상태라 가정하자. 다만 주어진 데이터의 클래스가 아닌 주어진 독립변수에 대한 종속변수의 값을 추정해야 한다. 분류 문제와 마찬가지로 주어진 데이터로 부터 미리 설정한 k값에 따라 open ball안에 k개의 다른 데이터 값이 들어올 때 까지 구간을 늘린다. \n",
    "\n",
    "그리고 k개의 학습 데이터가 들어왔을 때, 멈춘 후 그 k개의 종속변수 값의 평균값을 주어진 데이터의 종속변수로 추정한다.\n",
    "\n",
    "- Figure2.\n",
    "![](./image/img4.png)\n",
    "이미지 출저:https://gerardnico.com/wiki/data_mining/knn\n",
    "\n",
    "## Remark) \n",
    "- 가장 단순한 모델: 정해줘야할 매개변수는 거리를 어떻게 측정할건지와 k값 2개 밖에 없다.\n",
    "- 데이터의 분포를 고려할 필요가 없다(Non-parametric?)\n",
    "- 모델의 매개변수를 학습하는 과정이 필요 없음\n",
    "\n",
    "- 비교적 느린 분류(모든 학습데이터와의 거리를 측정해야함)\n",
    "- 차원이 큰 데이터(Feature가 많은 데이터)에 대해서는 잘 작동하지 않는 경향\n",
    "- Feature의 변동성에 따라 거리의 영향을 많이 받음\n",
    "\n",
    "- 보통 유클리드 거리($L_2$-norm) 사용\n",
    "- $L_1$-norm, $L_p$-norm 으로 확장 가능\n",
    "\n",
    "참고자료\n",
    "- https://helloacm.com/a-short-introduction-to-k-nearest-neighbors-algorithm/\n",
    "- http://chapter5k.blogspot.kr/2016/01/knnk-nearest-neighbors-r.html\n",
    "- https://proinlab.com/archives/2125\n",
    "- http://kkokkilkon.tistory.com/14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
