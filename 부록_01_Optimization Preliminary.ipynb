{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "머신러닝의 많은 부분에서 최적화가 심심치 않게 등장한다.\n",
    "\n",
    "필요한 지식들을 간단히 정리하고자 한다.\n",
    "\n",
    "# Duality\n",
    "\n",
    "머신러닝의 많은 문제들에 최적화가 포함되어 있다.\n",
    "\n",
    "최적화 문제가 어떤것인지 또,  최적화 지식이 필요한데, 간단히 살펴보고 가자.\n",
    "\n",
    "우선, 최적화 문제란, 최소화(혹은 최대화)하고자 하는 목적함수에 대해 제약조건을 만족하는 범위내에서 함수의 최적의 값을 구하는 문제이다.\n",
    "\n",
    "수학적 form으로 적으면 다음과 같이 적을 수 있다.\n",
    "## Definition) Optmization problem in standard form\n",
    "\\begin{aligned}\n",
    "min \\quad &f_0 (x)\n",
    "\\\\\n",
    "subject \\: to \\quad & f_i (x) \\le 0, \\quad i=1,...,m\n",
    "\\\\ & h_i (x) = 0, \\quad i=1,...,p\n",
    "\\end{aligned}\n",
    "\n",
    "- $x \\in \\mathbb{R}^n$ : 변수\n",
    "- $f_0 : \\mathbb{R}^n \\rightarrow \\mathbb{R}$ :목적함수 or 비용함수\n",
    "- $f_i : \\mathbb{R}^n \\rightarrow \\mathbb{R}, i=1,...,m$: 부등식 제약조건 함수\n",
    "- $h_i : \\mathbb{R}^n \\rightarrow \\mathbb{R}, i=1,...,p$: 등식 제약조건 함수\n",
    "\n",
    "책에 따라서는, 부등식 제약조건이 0보다 크게끔 세팅하는 경우도 있는데, 어느 쪽이든 통일을 시켜주면 되겠다.\n",
    "\n",
    "그리고 $f(x)$의 최솟값을 찾는 문제와 $-f(x)$의 최댓값을 찾는 문제는 같은 문제이므로, 경우에 맞게 목적함수를 최대화할지 최소화할지 결정하면 된다.\n",
    "\n",
    "이 때, 특별히 Convex Optimization 문제란, 목적함수가 미분가능한 convex함수이고, 부등식 제약조건은 미분가능한 convex함수, 등식제약조건은 affine함수로 주어진 문제를 말한다. 이를 정리하면 다음과 같다.\n",
    "\n",
    "## Definition) Convex Optimization Problem\n",
    "\\begin{aligned}\n",
    "min \\quad &f_0 (x)\n",
    "\\\\\n",
    "subject \\: to \\quad & f_i (x) \\le 0, \\quad i=1,...,m\n",
    "\\\\ & h_i (x) = a_{i}^{T}x - b_i = 0, \\quad i=1,...,p\n",
    "\\end{aligned}\n",
    "\n",
    "- $f_0,f_1, ... , f_m$: convex 함수\n",
    "\n",
    "이 때, 주어진 문제가 풀기 어려울 때, 해가 변하지 않게 문제를 바꾸어서 푸는 방법을 생각 해볼 수 있다.\n",
    "\n",
    "하지만 해가 바뀌지 않게 문제를 바꾸는 것은 굉장히 어려운 일이기 때문에, 먼저 원래 문제의 해(Primal optimal이라 한다)보다는 작은 값(underestimator)를 추정하는 문제로 바꾸어 그 추정값을 점점 키워나가 Primal Optimal에 가깝게 근접시키는 시도를 하고자 한다.\n",
    "\n",
    "먼저 시도해볼 수 있는 것이, 주어진 문제의 제약조건을 없애는 것이다. \n",
    "\n",
    "제약조건을 없애주기 위해 다음의 Indicator Function을 이용하여, 문제를 바꾸어 보았다.\n",
    "$$ min \\quad f_0 (x) + \\sum_{i=1}^{m} I_- (f_i (x) )) + \\sum_{i=1}^{p} I_0 (h_i (x))\n",
    "\\\\ where\\: I_-(u) = \\begin{cases} 0, & u \\le 0 \\\\ \\infty, & u > 0 \\end{cases},\\: I_0(u) = \\begin{cases} 0, & u = 0 \\\\ \\infty, & u \\ne 0 \\end{cases}$$\n",
    "\n",
    "하지만, 문자 그대로 제약조건을 없애주었을 뿐, 아무런 나아진 것이 없다.\n",
    "\n",
    "게다가 Indicator Function의 Graph를 한번 살펴보자.\n",
    "![](./image/sub/01/1.png)\n",
    "\n",
    "Indicator 함수를 이용함으로써 오히려 미분까지 불가능해지는 상태가 되었다.\n",
    "\n",
    "그래서 우리는 Smooth한 함수를 이용해서 Indicator Function을 Approximate 하여 사용하고자 한다.\n",
    "\n",
    "그 중 가장 간단한 Linear 함수를 이용해서 근사를 하려고 한다. \n",
    "\n",
    "즉, $I_-(u)$ 대신 $\\lambda u$, $I_0(u)$ 대신 $\\nu u$를 이용해서 근사하고자 한다.\n",
    "\n",
    "게다가, 원래 문제의 최소값보다는 작은 값을 추정하는 문제로 바꾸기 위해서는 $I_-(u)$를 근사하는데 사용한  $\\lambda u$에서 $\\lambda$값은 항상 양수가 되어야 한다.\n",
    "![](./image/sub/01/2.png)\n",
    "<center>모든 영역에서 원래 문제의 해보다 작은 값을 갖는다.</center>\n",
    "![](./image/sub/01/3.png)\n",
    "<center>어떤 영역에서 원래 문제의 해보다 큰 값을 갖게 될 수도 있다.</center>\n",
    "\n",
    "그래서 Linear 함수를 이용하여 제약조건을 없애고 원래 목적함수보다 작은 값을 추정하는 함수를 우리는 다음과 같이 Lagrangian으로 정의 한다.\n",
    "## Definition) Lagrangian\n",
    "Lagrangian $L:\\mathbb{R}^n \\times \\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R}$ associated with the given optimization problem is\n",
    "\n",
    "$$ L(x, \\lambda, \\nu) = f_0 (x) + \\sum_{i=1}^{m} \\lambda_i f_i (x) + \\sum_{i=1}^{p} \\nu h_i (x)$$\n",
    "\n",
    "- ${dom}L = (\\bigcap_{i=0}^{m} {dom}f_i \\cap \\bigcap_{i=1}^{p} {dom}h_i) \\times \\mathbb{R}^m \\times \\mathbb{R}^p$\n",
    "- $\\lambda_i$: Lagrangian multiplier associated with $f_i (x) \\le 0$ : 부등식 제약조건에 대한 라그랑지 승수\n",
    "- $\\nu_i$: Lagrangian mulitplier associated with $h_i (x) = 0 $: 등식 제약조건에 대한 라그랑지 승수\n",
    "\n",
    "이제, Lagrangian함수를 $x$에 대해 minimize한 함수를 Lagrangian Dual Function이라 정의한다.\n",
    "\n",
    "## Definition) Lagrange Dual Function\n",
    "The Lagrange dual function $g:\\mathbb{R}^m \\times \\mathbb{R}^p \\rightarrow \\mathbb{R}$ is defined by\n",
    "\\begin{aligned}\n",
    "g(\\lambda, \\nu) &= inf_{x \\in D} L(x, \\lambda, \\nu)\n",
    "\\\\\n",
    "& = inf_{x \\in D} (f_0 (x) + \\sum_{i=1}^{m} \\lambda_i f_i (x) + \\sum_{i=1}^{p} \\nu h_i (x)\n",
    "\\end{aligned}\n",
    "\n",
    "- where $D = (\\bigcap_{i=0}^{m} {dom}f_i \\cap \\bigcap_{i=1}^{p} {dom}h_i)$ : 원래 문제의 정의역\n",
    "\n",
    "## Remark)\n",
    "지금까지의 여정을 잠깐 정리하면, 원래 최적화 문제(이를 보통 Primial problem이라 함.)을 풀기 어려우니, 찾고자 하는 최솟값(primal optimal)보다는 작은 값을 찾는 문제를 만들어서 그 값을 점점 키워나가려는 시도를 한다고 했다.\n",
    "\n",
    "가장 먼저 한 일이 제약조건을 없애주기 위해 indicator함수를 사용했고, indicator함수는 별 효과가 없어보여 이 함수를 linear 함수로 근사하였다. 이때 부등식 제약조건에 해당하는 linear 계수를 양수로 잡아오면, $f_0$보다 항상 작은 값을 추정하게 된다.\n",
    "\n",
    "이렇게 만든 함수가 바로 Lagrangian이 되고, 이제 이 함수를 $x$에 대해 최소화시킨 함수를 Lagrange dual function이라고 했다.\n",
    "\n",
    "Lagrange dual function은 $\\lambda,\\nu$를 어떻게 선택하느냐에 따라 달라지는데, 어떤 녀석을 선택하든 잘 정의가 되었다면 이 함수의 값은 $f_0$보다는 작은 값을 도출하게 될 것이다. \n",
    "\n",
    "이러한 성질을 Lower bound property라고 한다.\n",
    "\n",
    "## Lower bound property)\n",
    "If $\\lambda \\succeq 0$, then $g(\\lambda, \\nu) \\le {inf}\\: f_0 (x) \\overset{\\underset{\\mathrm{def}}{}}{=} p^* $\n",
    "\n",
    "$\\because$ 만약 $\\tilde{x} \\in D$ 이고, $\\lambda \\succeq 0$이면,\n",
    "$$f_0 (\\tilde{x} ) \\ge L(\\tilde{x}, \\lambda , \\nu) = f_0 (\\tilde{x}) + \\sum_{i=1}^{m} \\lambda_i f_i (\\tilde{x}) + \\sum_{i=1}^{p} \\nu h_i (\\tilde{x}) \\ge inf_x L(x,\\lambda , \\nu) = g(\\lambda , \\nu)$$\n",
    "\n",
    "즉, 정의역에 있는 모든 $x$에 대해 항상 위의 부등식이 성립하므로, 정의역 중 함수값이 가장 작아지는 optimal variable에 대해서도 성립하므로,\n",
    "\n",
    "$$ p^* \\ge  g(\\lambda , \\nu)$$ 임을 알 수 있다.\n",
    "\n",
    "그러면 이제, 우리는 라그랑지 승수를 변경해가며 Lagrange Dual Function의 값을 최대한 키우는 일을 할 것이다.\n",
    "\n",
    "그래서 Primal Optimal과의 간격을 좁히면서 근사해나가는것이 바로 Dual Problem이다.\n",
    "\n",
    "## Definition) Lagrange Dual Problem\n",
    "\\begin{aligned}\n",
    "max \\quad & g(\\lambda , \\nu)\n",
    "\\\\\n",
    "subject \\: to \\quad &\\lambda \\succeq 0\n",
    "\\end{aligned}\n",
    "\n",
    "- 일반적으로 Dual Problem은 Primal optimal value(denoted by $p^*$)의 가장 좋은 lower bound를 찾는 문제이다.\n",
    "- 원래 문제가 convex이든 아니든 상관없이, dual problem은 convex problem이 된다.\n",
    "- Dual problem의 optimal value을 $d^*$로 쓰자.\n",
    "\n",
    "## Weak Duality and Strong Duality\n",
    "Dual Function의 모든 값은 $p^*$의 lower bound가 되므로, Dual optimal인 $d^*$도 $p^*$보다 작게 될텐데 이러한 성질을 weak duality라고 한다.\n",
    "$$d^* \\le p^*$$\n",
    "\n",
    "앞서 설명한 lower bound property에 의해서 모든 최적화 문제는 Weak duality가 성립한다고 할 수 있다.\n",
    "\n",
    "하지만, 우리의 희망은 $d^*$와 $p^*$가 같게 되는 것이다.\n",
    "\n",
    "$d^* = p^*$일 때를 우리는 최적화 문제가 Strong Duality가 성립한다고 이야기한다.\n",
    "\n",
    "일반적인 최적화 문제에서는 weak duality만 성립하고, strong duality는 성립하지 않는다.\n",
    "\n",
    "그렇다면 언제 strong duality가 성립할까?\n",
    "\n",
    "strong duality가 성립하게 하는 충분조건들을 constraint qualification이라 한다.\n",
    "\n",
    "(i.e constraint qualification $\\Longrightarrow$ strong duality)\n",
    "\n",
    "많은 constraint qualification이 있는데, 앞서 우리는 convex 최적화 문제를 정의했고 주로 convex에 초점을 맞추고 있으므로,\n",
    "\n",
    "convex 최적화 문제 중 strong duality를 보장하는 constraint qualification을 살펴보자.\n",
    "\n",
    "그 중 소개할 조건 중 하나가 Slater's constraint condition이다.\n",
    "\n",
    "## Slater's constraint condition)\n",
    "If there exists an $x^* \\in relint(D)$ such that $f_i(x) < 0$ for nonlinear inequality constraints $f_i$ in a convex optimization problem, then strong duality holds\n",
    "\n",
    "i.e) In convex optimization problem, if $^\\exists x^* \\in relint(D)$ such tat\n",
    "- $f_i (x^*) \\le 0, \\: i=1, ... ,k$ (the linear constraint)\n",
    "- $f_i (x^*) < 0, \\: i=k+1, ..., m$ (the nonlienar constraint)\n",
    "\n",
    "then strong duality holds.\n",
    "\n",
    "In particular, if pirmal optimal value is finite($p^* \\ge -\\infty$), then it guarantees that dual optimum is attained\n",
    "\n",
    "간단히 말하면, primal 문제의 비선형 부등식 제약조건에 대해 완전히 0보다 작게하는 점이 정의역에 존재하면, strong duality가 성립한다는 의미이다. 게다가 만약 primal 문제의 최솟값이 유한값으로 존재한다면, dual 문제의 최댓값의 존재성도 보장된다.\n",
    "\n",
    "pf) Stephen Boyd_Convex Optimization p.234 참고\n",
    "\n",
    "자 이제 이 정리를 이용하여, 주어진 convex 최적화 문제가 풀기가 어렵다면, Slater's condition을 확인하여 dual 문제로 바꾸어 풀 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Optimality Condition\n",
    "\n",
    "그러면, 최적화 문제를 푸는데 있어서, 현재 구한 값이 optimal solution인지 아닌지 확인하는 방법이 필요하다.\n",
    "\n",
    "먼저, optimal point는 어떤 성질들을 만족하는지 살펴보자.\n",
    "\n",
    "strong duality가 성립하는 최적화 문제(꼭 convex일 필요는 없음)에서 $x^*$를 primal optimal point, $\\lambda^*, \\nu^*$를 dual optimal point라 하자.\n",
    "\n",
    "먼저 $x^*,\\lambda^*, \\nu^*$은 정의역 안에 있는 점들이므로, 기본적인 제약조건은 만족해야 한다.\n",
    "\n",
    "즉,\n",
    "\n",
    "$$f_i(x^*) \\le 0 , i=1,...,m \\quad (primal\\: feasiblity)\n",
    "\\\\ h_i(x^*) = 0 , i=1,...p \\quad (primal\\: feasiblity)\n",
    "\\\\ \\lambda_i^* \\ge 0, i=1,...,m \\quad (dual\\: feasiblity)$$ \n",
    "\n",
    "그리고 strong duality가 성립한다는 조건으로 부터 다음을 얻을 수 있다.\n",
    "\n",
    "\\begin{aligned}\n",
    "f_0(x^*) & = g(\\lambda^*, \\nu^*) \n",
    "\\\\ &= inf_{x} \\: L(x, \\lambda^*, \\nu^*) = inf_{x} \\:( f_0 (x) + \\sum_{i=1}^{m} \\lambda_i^* f_i (x) + \\sum_{i=1}^{p} \\nu^* h_i (x))\n",
    "\\\\ &\\ge f_0 (x^*) + \\sum_{i=1}^{m} \\lambda_i^* f_i (x^*) + \\sum_{i=1}^{p} \\nu^* h_i (x^*) \\quad(1)\n",
    "\\\\ &\\ge f_0(x^*) \\quad(2)\n",
    "\\end{aligned}\n",
    "\n",
    "결국 모든 부등호가 등식이 성립하게 된다.\n",
    "\n",
    "(1)번 부등식이 등식으로 바뀌면서, $x^*$가  $L(x, \\lambda^*, \\nu^*)$을 최소화시키는 점이라는 걸 알 수 있다.\n",
    "\n",
    "즉,\n",
    "\n",
    "$$ \\nabla_x L(x^*, \\lambda^*, \\nu^*) = \\nabla f_0 (x) + \\sum_{i=1}^{m} \\lambda_i^* \\nabla f_i (x) + \\sum_{i=1}^{p} \\nu^* \\nabla h_i (x) = 0 \\quad (Stationary \\: Condition)$$\n",
    "\n",
    "그리고 (2)번 부등식이 등식으로 바뀌면서, $\\sum_{i=1}^{m} \\lambda_i^* f_i (x^*)=0$ 임을 알 수 있다.\n",
    "\n",
    "이 때, $\\lambda_i^* \\ge 0$이고, $f_i (x^*) \\le 0$이므로 $\\lambda_i^* f_i (x^*) \\le 0$이 된다. ($i=1,...,m$)\n",
    "\n",
    "즉 0보다 작거나 같은 녀석들을 모두 더해서 0이 되므로 각각이 모두 0이 됨을 알 수 있다.\n",
    "\n",
    "즉,\n",
    "\n",
    "$$ \\lambda_i^* f_i (x^*) = 0, \\quad i=1,...,m \\quad ({Complementary \\: Slackness})$$\n",
    "\n",
    "정리하면, strong duality가 성립하는 최적화 문제에 대해 optimal point $(x^*, \\lambda^*, \\nu^*)$는 위의 4가지 조건(pirmal feasibilty, dual feasiblity, stationary, complementary slackness)을 만족한다.\n",
    "\n",
    "이 4가지 조건을 합쳐서 Karush-Khun-Tucker(KKT) condition이라 한다.\n",
    "\n",
    "## KKT conditions)\n",
    "\n",
    "다음 4가지의 조건을 최적화 문제의 KKT 조건이라 한다.\n",
    "\n",
    "- 1.Primal feasiblity : $f_i(x) \\le 0 ,\\quad i=1,...,m$ , $ h_i(x) = 0 ,\\quad i=1,...p$\n",
    "- 2.Dual feasibility : $\\lambda_i \\ge 0,\\quad i=1,...,m$\n",
    "- 3.Complementary slackness : $\\lambda_i f_i (x) = 0,\\quad i=1,...,m $\n",
    "- 4.Stationary : $\\nabla_x L(x, \\lambda, \\nu) = \\nabla f_0 (x) + \\sum_{i=1}^{m} \\lambda_ \\nabla f_i (x) + \\sum_{i=1}^{p} \\nu \\nabla h_i (x) = 0$\n",
    "\n",
    "우리는 KKT 조건의 유도과정으로 부터 strong duality가 성립하는 일반적인 최적화 문제에서 최적의 해 $(x^*, \\lambda^*, \\nu^*)$는 KKT 조건을 만족함을 알 수 있다.\n",
    "\n",
    "$$ Strong \\: duality \\: 성립, \\: (x, \\lambda, \\nu): optimal \\Longrightarrow KKT \\: 조건 \\: 만족$$\n",
    "\n",
    "그러면, 우리가 희망하는 것은 어떤 녀석들이 Optimal한지 확인하는 것이다.\n",
    "\n",
    "앞서 살펴본 KKT 조건은 convex 최적화 문제에서 optimal을 보장하는 충분조건이 된다.\n",
    "\n",
    "## KKT conditions for convex problem)\n",
    "If $\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}$ satisfy KKT for a convex problem, then they are optimal.\n",
    "\n",
    "Convex 최적화 문제에서 $\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}$가 KKT 조건을 만족한다면, 그들은 optimal이다.\n",
    "\n",
    "$\\because$)\n",
    "\n",
    "$\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}$이 KKT조건을 만족하므로,\n",
    "\n",
    "complementary slackness로 부터,\n",
    "\n",
    "$$ \\lambda_i f_i (x) = 0,\\quad i=1,...,m \\quad \\Longrightarrow \\quad f_0(\\tilde{x}) = L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}) \\quad (*)$$\n",
    "\n",
    "Staitionary로 부터,\n",
    "\n",
    "\\begin{aligned}\n",
    "\\nabla_x L(\\tilde{x}, \\lambda, \\nu) = 0 \\quad &\\Longrightarrow \\quad \\tilde{x} \\: minimize \\: L(x,\\tilde{\\lambda}, \\tilde{\\nu})\n",
    "\\\\ &\\Longrightarrow \\quad g(\\tilde{\\lambda}, \\tilde{\\nu})=L(\\tilde{x},\\tilde{\\lambda}, \\tilde{\\nu}) \\quad(**)\n",
    "\\end{aligned}\n",
    "\n",
    "그러면, 다음과 같은 부등식이 성립한다.\n",
    "\n",
    "\\begin{aligned}\n",
    "d^* & \\ge g(\\tilde{\\lambda}, \\tilde{\\nu})\n",
    "\\\\ & = L(\\tilde{x}, \\tilde{\\lambda}, \\tilde{\\nu}) \\quad (2)\n",
    "\\\\ & = f_0 (\\tilde{x}) \\quad (1)\n",
    "\\\\ & \\ge p^*\n",
    "\\end{aligned}\n",
    "\n",
    "그리고 일반적으로 weak duality는 항상 성립하므로,\n",
    "\n",
    "$$p^* \\ge d^*$$\n",
    "\n",
    "위의 두 부등식을 이용하면,\n",
    "\n",
    "$$p^* = d^* = f_0 (\\tilde{x}) = g(\\tilde{\\lambda}, \\tilde{\\nu})$$\n",
    "\n",
    "정리를 하면, convex 최적화 문제에서는\n",
    "\n",
    "$$ KKT \\Longrightarrow Optimal$$\n",
    "\n",
    "## Remark)\n",
    "자 앞서 했던 이야기를 모두 정리해보자.\n",
    "\n",
    "convex 최적화 문제이든지 아니든지 strong duality가 성립하면, optimal point는 KKT 조건을 만족한다.\n",
    "\n",
    "반대로는 convex 최적화 문제에서 KKT를 만족하는 point가 optimal point가 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
