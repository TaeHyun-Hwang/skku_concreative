{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayes Theorem_베이즈 이론\n",
    "\n",
    "## Recall)\n",
    "\n",
    "- Conditional Probability_조건부 확률:\n",
    " <br> $P(B|A)$: 사건 A에 대한 사건 B가 일어날 확률\n",
    "   $$P(B|A)=\\frac{P(A\\cap B)}{P(A)}$$\n",
    "\n",
    "- Bayes Theorem_베이즈 정리\n",
    "    <br>: 사후확률은 사전확률과 가능도의 곱에 비례한다.\n",
    "   $$P(v|D)=\\frac{P(D|v)P(v)}{P(D)}$$\n",
    "where\n",
    " - v: 데이터의 클래스\n",
    " - D : 데이터\n",
    " - P(v): Prior probability(사전확률)\n",
    " - P(D|v): Likelihood(가능도)\n",
    " - P(v|D): Posterior probability(사후확률)\n",
    "        \n",
    "이제 주어진 데이터와 클래스에(학습 데이터) 대해 새로운 데이터가 들어왔을 때 어떤 클래스에 분류할 것인지 생각해보자.\n",
    "\n",
    "이때, 주어진 데이터에 대해 가장 그럴듯한 클래스에 데이터를 분류하는게 합리적이다. 이러한 판단을 우리는 사후확률이 최대가 되도록 할 것이다.\n",
    "\n",
    "이러한 클래스를 우리는 Maximize a Posterior를 줄여 MAP라고 부르고 다음과 같이 결정된다.\n",
    "\n",
    "$$ v_{MAP} = argmax_{v \\in V} P(v|D)\n",
    "\\\\ = argmax_{v \\in V} \\frac{P(D|v)P(v)}{P(D)} \n",
    "\\\\ = argmax_{v \\in V} P(D|v) P(v)$$\n",
    "\n",
    "이 때 클래스의 분포가 균일하다면, MAP와 MLE가 같게 된다. 즉, 만약 모든 i,j에 대해 $P(v_j)=P(v_i)$라면,\n",
    "$$v_{ML} = v_{MAP} = argmax_{v \\in V} P(D|v)$$\n",
    "\n",
    "예제를 통해 이해해보자.\n",
    "\n",
    "## Example)\n",
    "Does patient have cancer or not?\n",
    "<br> A patient takes a lab test and the result comes back positive.\n",
    "     The test returns a correct possible result in 98% of the cases\n",
    "     in which the disease is actually present, and a correct negative\n",
    "     result in 97% of the cases in which the disease is not present.\n",
    "     Furthermore, 0.8% of the entire population have this cancer.\n",
    "\n",
    "한 환자가 실험실 테스트에서 암진단을 받았다. \n",
    "        실험실 테스트는 암인 환자를 대상을 98% 정확도로 암이 맞다고 진단하고\n",
    "        암이 아닌 환자를 대상으로 97% 정확도로 암이 아니라고 진단한다. 그리고 전체 환자 중 0.8%가 암인 환자라고 한다.\n",
    "        이 경우 이 환자는 암인지 아닌지 판단하여라.\n",
    "        \n",
    "이 때 우리가 확인해봐야할 데이터는 실험실 테스트로 부터 암이라고 진단 받은 환자이다. \n",
    "\n",
    "'$v_1 =$암, $v_2 = $암이 아니다, $ + = $암이라고 진단, $ - = $암이 아니라고 진단' 이라 하자. 그러면, 다음을 얻을 수 있다.\n",
    "\n",
    "$$ P(v_1) = 0.008, P(v_2)=0.992\n",
    "\\\\ P(+|v_1) = 0.98, P(-|v_1) = 0.02\n",
    "\\\\ P(+|v_2) = 0.03, P(-|v_2) = 0.97$$\n",
    "\n",
    "MAP를 이용하여 암이라고 진단 받은 환자의 암인지의 여부를 판단해보자.\n",
    "\n",
    "다음으로 부터\n",
    "\n",
    "$$v_{MAP} = argmax_{v \\in V} P(v|+) = argmax_{v \\in V} P(+|v)*P(v)$$\n",
    "\n",
    "$$ P(v_1|+) \\propto \\ P(+|v_1)*P(v_1) = 0.98 * 0.008 = 0.0078\n",
    "\\\\ P(v_2|+) \\propto P(+|v_2)*P(v_2) = 0.03 * 0.992 = \\mathbf{0.0298} $$\n",
    "\n",
    "우리는 암이라고 진단 받은 환자는 암이 아니다고 진단하는 것이 타당하다.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remark)\n",
    "\n",
    "위의 경우 입력 데이터의 Feature가 실험실 테스트의 결과인 1개 였다. \n",
    "\n",
    "그렇다면 입력데이터의 Feature가 여러개인 경우에 생각해보자.\n",
    "\n",
    "다음의 데이터를 생각해보자.\n",
    "\n",
    "그림1. 나이브 베이즈 예제 데이터\n",
    "![](./image/05/05_01.png)\n",
    "\n",
    "데이터를 설명하면, 바깥 날씨(outlook), 기온(Temperature), 습도(Humidity), 바람(WInd)의 상태에 따라 테니스를 할지 말지에 대한 과거 데이터이다.\n",
    "\n",
    "이제 입력데이터로 (Outlook, Temperature, Humidity, Wind)를 받아 출력데이터로 1(Yes Playtennis), 0(No Play Tennis)의 경우를 생각해보자.\n",
    "\n",
    "위의 주어진 데이터에 새로운 상태로 다음이 들어왔을 때 Tennis play 가 Yes일지 No일지를 판단해보자.\n",
    "\n",
    "그림2. 새로운 예제\n",
    "![](./image/05/05_02.png)\n",
    "\n",
    "앞어 설명한 예제처럼 최대사후확률로 클래스를 판단할 경우 다음의 확률을 계산하면 된다.\n",
    "\n",
    "$$ v_{map} = argmax_{v_j \\in V}P(v_j | outlook, temperature, humidity, wind) \n",
    "\\\\ = argmax_{v_j \\in V} \\frac{P( outlook, temperature, humidity, wind | v_j)* P(v_j)}{P(outlook, temperature, humidity, wind)}\n",
    "\\\\ = argmax_{v_j \\in V} P( outlook, temperature, humidity, wind | v_j) * P(v_j)\n",
    "\\\\ where, \\quad V= \\left\\{ Yes, NO \\right\\}$$\n",
    "\n",
    "그렇다면 생기는 문제가, $P( (outlook, temperature, humidity, wind) | v_j)$ 이 확률을 어떻게 계산할 것인가이다.\n",
    "\n",
    "이 때 우리는 조건부 독립을 가정한다.\n",
    "\n",
    "## Definition)\n",
    "- Conditionally independence_조건부 확률 독립\n",
    "    <br> $A$ and $B$ are conditionally independent given X if and only if\n",
    "    $$P(A\\cap B|X)=P(A|X)P(B|X)$$\n",
    "    \n",
    "이제, 데이터의 클래스에 대한 입력 데이터의 Feature간의 조건부 독립을 가정하여 계산을 하고자 한다.\n",
    "\n",
    "하지만, 실제로는 클래스에 대한 Feature간의 독립을 가정하는데 무리가 있지만 계산을 위해 필요한 가정이다.\n",
    "\n",
    "때문에 이 분류의 방법이 Naive, '순진한'이란 형용사가 붙는 이유이다.\n",
    "\n",
    "클래스에 대한 데이터의 조건부 독립을 가정하면, $P(outlook, temperature, humidity, wind \\,| v_j)$의 확률은 다음과 같다.\n",
    "\n",
    "$$P(outlook, temperature, humidity, wind \\,|v_j) = P(outlook\\,|v_j)*P(temperature \\,|v_j)*P(humidity \\,|v_j)*P(wind\\,|v_j)$$\n",
    "\n",
    "그렇다면 나이브 베이즈 분류에 의한 클래스는 다음과 같이 결정 된다.\n",
    "\n",
    "$$v_{NB} = argmax_{v_j \\in V} P(v_j) *P(outlook|v_j)*P(temperature |v_j)*P(humidity |v_j)*P(wind|v_j)$$\n",
    "\n",
    "그렇다면 주어진 예제를 나이브 베이즈 분류를 이용하여 분류해보자..\n",
    "\n",
    "주어진 새로운 예제가 다음과 같으니, 필요한 확률을 계산해보면\n",
    "![](./image/05/05_02.png)\n",
    "\n",
    "$$P(v_j = Yes) = 9/14, P(v_j = No) = 5/14\n",
    "\\\\ P(Sunny|Yes) = 2/9, P(Sunny|No) = 3/5\n",
    "\\\\ P(Cool|Yes) = 3/9, P(Cool|No) = 1/5\n",
    "\\\\ P(High|Yes) = 3/9, P(High|No) = 4/5\n",
    "\\\\ P(Strong | Yes)= 3/9, P(Strong|No) 3/5$$\n",
    "\n",
    "이를 이용하여 $P(v_j) *P(outlook|v_j)*P(temperature |v_j)*P(humidity |v_j)*P(wind|v_j)$ 을 계산하면,\n",
    "\n",
    "$$P(Yes) *P(Sunny|Yes)*P(Cool |Yes)*P(High|Yes)*P(Strong| Yes)= (9/14)*(2/9)*(3/9)*(3/9)*(3/9) \\approx 0.005\n",
    "\\\\P(No) *P(Sunny|No)*P(Cool |No)*P(High|No)*P(Strong|No)= (5/14)*(3/5)*(1/5)*(4/5)*(3/5) \\approx 0.021$$\n",
    "\n",
    "때문에 주어진 데이터에 비추어 볼 때 나이브 베이즈 분류는 \"No\"로 분류하게 된다.\n",
    "\n",
    "## Remark)\n",
    "나이브 베이즈 분류의 한계\n",
    "- 조건부 독립\n",
    "\n",
    "$$P(d_1, d_2, ... , d_n | v_j ) = \\prod_{i} P(d_i | v_j )$$\n",
    "\n",
    "이 조건이 실제 데이터에 있어서 무리한 가정일 수 있다.\n",
    "\n",
    "- 새로운 데이터의 Feature가 기존의 학습데이터에 없는 경우\n",
    "\n",
    "예를 들어 새로운 데이터 $(a_1, a_2, ... ,a_n)$이 들어 왔다고 하자. 하지만 k번째 Feature인 $a_k$의 Feature값이 기존의 학습데이터에는 없는 경우라면 $P(a_k | v_j) = 0$이 되고 따라서, $P(a_1,a_2, ... , a_n | v_j ) = P(a_1 | v_j ) * P(a_2 | v_j) * ... *P(a_n | v_j) = 0$ 이 된다.\n",
    "따라서 이런 경우에는 분류가 불가능하게 된다.\n",
    "\n",
    "이런 문제는 학습데이터에 없는 feature에 대한 확률이 0이 되서 생겨나는 문제이므로 이를 약간 smoothing하여 문제를 해결한한다.\n",
    "\n",
    "smoothing을 이용하여 liklihood를 계산하면,\n",
    "\n",
    "$$ P(a_k | v_j ) = \\frac{ \\#(a_k | v_j) + \\alpha}{ \\#(a_k | v_j) + \\alpha n}$$\n",
    "\n",
    "where\n",
    "- $\\#(a_k | v_j)=$ the number of times feature $a_k$ appears in class $v_j$\n",
    "- $n=$ the number of features\n",
    "\n",
    "보통 $\\alpha=1$로 두는데 이런 경우를 우리는 Laplace smoothing이라고 한다.\n",
    "\n",
    "참고로, $\\alpha <1 $ 인 경우는 Lidstone smoothing 이라고 한다.\n",
    "\n",
    "그렇다면 위의 예제에서 만약 새로운 데이터가 다음과 같이 들어왔다고 하자.\n",
    "\n",
    "$$(Outlook = Sunny, Temperature = Cool, Humidity = High, Wind = None)$$\n",
    "\n",
    "이 경우 Laplace smoothing을 이용하여 계산해보면,\n",
    "\n",
    "$$P(v_j = Yes) = 9/14, P(v_j = No) = 5/14\n",
    "\\\\ P(Sunny|Yes) = (2+1)/(9+4), P(Sunny|No) = (3+1)/(5+4)\n",
    "\\\\ P(Cool|Yes) = (3+1)/(9+4), P(Cool|No) = (1+1)/(5+4)\n",
    "\\\\ P(High|Yes) = (3+1)/(9+4), P(High|No) = (4+1)/(5+4)\n",
    "\\\\ P(None | Yes)= (0+1)/(9+4), P(None|No) (0+1)/(5+4)$$\n",
    "\n",
    "이를 이용하여 $P(v_j) *P(outlook|v_j)*P(temperature |v_j)*P(humidity |v_j)*P(wind|v_j)$ 을 계산하면,\n",
    "\n",
    "$$P(Yes) *P(Sunny|Yes)*P(Cool |Yes)*P(High|Yes)*P(Strong| Yes)= (9/14)*(3/13)*(4/13)*(4/13)*(1/13) \\approx 0.00108\n",
    "\\\\P(No) *P(Sunny|No)*P(Cool |No)*P(High|No)*P(Strong|No)= (5/14)*(4/9)*(2/9)*(5/9)*(1/9) \\approx 0.0021$$\n",
    "\n",
    "그래도 역시 테니스를 치지 않겠다는 걸로 결론이 나게 된다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
