{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Some optimization Preliminary\n",
    "이 문제를 풀기 위해서 약간의 수학적 지식이 필요한데, 간단히 살펴보고 가자.\n",
    "\n",
    "convex optimization 문제란, 목적함수가 미분가능한 convex함수이고, 부등식 제약조건은 미분가능한 convex함수, 등식제약조건은 affine함수로 주어진 문제를 말한다. 이를 정리하면 다음과 같다.\n",
    "\n",
    "## Definition)\n",
    "![](./image/07/sub/1.png)\n",
    "이미지 출저: https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf \n",
    "\n",
    "이 때, 주어진 문제가 풀기 어려울 때, 해가 변하지 않게 문제를 바꾸어서 푸는 방법을 생각 해볼 수 있다.\n",
    "\n",
    "하지만 해가 바뀌지 않게 문제를 바꾸는 것은 굉장히 어려운 일이기 때문에, 먼저 원래 문제의 해(Primal optimal이라 한다)보다는 작은 값(underestimator)를 추정하는 문제로 바꾸어 그 추정값을 점점 키워나가 Primal Optimal에 가깝게 근접시키는 시도를 하고자 한다.\n",
    "\n",
    "먼저 시도해볼 수 있는 것이, 주어진 문제의 제약조건을 없애는 것이다. \n",
    "\n",
    "하지만, 문자 그대로 제약조건을 없애주었을 뿐, 아무런 나아진 것이 없다.\n",
    "\n",
    "제약조건을 없애주기 위해 다음의 Indicator Function을 이용하여, 문제를 바꾸어 보았다.\n",
    "![](./image/07/sub/3.png)\n",
    "\n",
    "하지만, 문자 그대로 제약조건을 없애주었을 뿐, 아무런 나아진 것이 없다.\n",
    "\n",
    "게다가 Indicator Function의 Graph를 한번 살펴보자.\n",
    "![](./image/07/sub/4.png)\n",
    "\n",
    "Indicator 함수를 이용함으로써 오히려 미분까지 불가능해지는 상태가 되었다.\n",
    "\n",
    "그래서 우리는 Smooth한 함수를 이용해서 Indicator Function을 Approximate 하여 사용하고자 한다.\n",
    "\n",
    "그 중 가장 간단한 Linear 함수를 이용해서 근사를 하려고 한다. \n",
    "\n",
    "즉, $I_-(u)$ 대신 $\\lambda u$, $I_0(u)$ 대신 $\\nu u$를 이용해서 근사하고자 한다.\n",
    "\n",
    "게다가, 원래 문제의 최소값보다는 작은 값을 추정하는 문제로 바꾸기 위해서는 $I_-(u)$를 근사하는데 사용한  $\\lambda u$에서 $\\lambda$값은 항상 양수가 되어야 한다.\n",
    "![](./image/07/sub/5.png)\n",
    "<center>모든 영역에서 원래 문제의 해보다 작은 값을 갖는다.</center>\n",
    "![](./image/07/sub/6.png)\n",
    "<center>어떤 영역에서 원래 문제의 해보다 큰 값을 갖게 될 수도 있다.</center>\n",
    "\n",
    "그래서 Linear 함수를 이용하여 제약조건을 없앤 함수를 우리는 다음과 같이 Lagrangian으로 정의 한다.\n",
    "## Definition)\n",
    "![](./image/07/sub/2.png)\n",
    "이미지 출저: https://web.stanford.edu/~boyd/cvxbook/bv_cvxslides.pdf\n",
    "\n",
    "이 때, $\\lambda_i$를 부등식 제약조건의 라그랑지 승수, $\\nu_i$를 등식 제약조건의 라그랑지 승수라고 한다.\n",
    "\n",
    "이제, Lagrangian함수를 $x$에 대해 minimize한 함수를 Lagrangian Dual Function이라 정의하고 수식으로 보면 다음과 같다.\n",
    "![](./image/07/sub/7.png)\n",
    "\n",
    "## Remark)\n",
    "우리는 앞서 원래 최적화 문제의 제약조건을 없앰과 동시에 원래 문제의 해보다는 약한 값을 추정하게끔 Lagrangin Dual Function을 정의 하였다.\n",
    "\n",
    "부등식 제약조건의 라그랑지 승수가 양수가 된다면, Lagrangian Dual Function의 값은 늘 Primal Optimal보다 작게 나오게 될텐데, \n",
    "\n",
    "이를 Lower bound property라고 한다.\n",
    "![](./image/07/sub/8.png)\n",
    "\n",
    "그러면 이제, 우리는 라그랑지 승수를 변경해가며 Lagrangian Dual Function의 값을 최대한 키우는 일을 할 것이다.\n",
    "\n",
    "그래서 Primal Optimal과의 간격을 좁히면서 근사해나가는게 Dual Problem을 정의 하는 이유이다.\n",
    "\n",
    "## Definition and Remark)\n",
    "![](./image/07/sub/9.png)\n",
    "\n",
    "- 일반적으로 Dual Problem은 Primal optimal(denoted by $p^*$)의 가장 좋은 lower bound를 찾는 문제이다.\n",
    "- 원래 문제가 convex이든 아니든 상관없이, dual problem은 convex problem이 된다. 그리고 dual problem의 optimal solution을 $d^*$로 쓰자.\n",
    "\n",
    "## Weak Duality and Strong Duality\n",
    "Dual Function의 모든 값은 $p^*$의 lower bound가 되므로, Dual optimal인 $d^*$도 $p^*$보다 작게 될텐데 이러한 성질을 weak duality라고 한다.\n",
    "$$d^* \\le p^*$$\n",
    "\n",
    "우리의 희망은 $d^*$와 $p^*$가 같게 되는 것이다. \n",
    "\n",
    "$d^* = p^*$일 때를 우리는 Strong Duality라고 한다.\n",
    "\n",
    "# Slater's Constraint condition\n",
    "일반적으로 최적화 문제에서는 weak duality만 성립하고, strong duality는 성립하지 않는다.\n",
    "\n",
    "왠지 원래 문제가 convex problem이 되면 strong duality가 성립할 것 같은 그럴듯한 생각을 할 수 있는데, 사실 한가지 조건이 더 필요한데 그것이 바로 Slater's condition이다.\n",
    "\n",
    "## Slater's constraint condition\n",
    "![](./image/07/sub/10.png)\n",
    "간단히 말하면, 부등식 제약조건 중 부등하고 strict하게 작아지게 하는 $x$가 현재 domain안에 있다면, strong duality와 weak duality가 성립한다는 의미이다.\n",
    "\n",
    "### NOTE\n",
    "Slater's condition은 strong duality 뿐만 아니라, Dual optimum의 존재성까지 보장해준다.\n",
    "\n",
    "그렇다면, 우리는 주어진 문제가 convex 문제라면, 그리고 그 문제 그대로 풀기가 어렵다면, Slater's condition을 확인하여 dual 문제로 바꾸어 풀 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# KKT condition\n",
    "\n",
    "그러면, 최적화 문제를 푸는데 있어서, 현재 구한 값이 optimal solution인지 아닌지 확인하는 방법이 필요하다.\n",
    "\n",
    "이러한 조건을 Optimality condition이라고 하고, 그 중 하나인 KKT condition에 대해 살펴보자.\n",
    "\n",
    "다음과 같은 optimization 문제(꼭 convex일 필요는 없음)가 있다고 하자.\n",
    "![](./image/07/sub/11.png)\n",
    " \n",
    "이 때, $x^*$를 primal optimal point, $(\\lambda^*,\\nu^*)$를 dual optimal point라 하고, strong duality가 성립한다고 가정하자.\n",
    "\n",
    "- Stationary condition\n",
    "$x^*$ $L(x,\\lambda^*,\\nu^*)$을 최소화 시키는 값이므로 $L$을 $x$에 대해 미분하면, 0이 된다.\n",
    "즉, \n",
    "![](./image/07/sub/12.png)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
